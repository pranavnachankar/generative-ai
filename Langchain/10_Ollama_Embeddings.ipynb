{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69d0fde-01a6-4da3-ace6-4eb1d7b2fe73",
   "metadata": {},
   "source": [
    "## [Ollama Embeddings](https://ollama.com/)\n",
    "\n",
    "- It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.\n",
    "- Ollama supports embedding models, making it possible to build RAG (Retrieval-Augmented Generation) applications that combine text prompts with existing documents or other data\n",
    "\n",
    "https://github.com/ollama/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f322806-26f0-4f87-a041-413b1e6f0b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = (\n",
    "    OllamaEmbeddings(model=\"gemma2:2b\") # by default Embeddings will use `llama2`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ecb6cf-9395-4396-963e-b333fafc95cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r1 = embeddings.embed_documents(\n",
    "    [\n",
    "        \"Alpha is first letter of Greek alphabate\",\n",
    "        \"Beta is first letter of Greek alphabate\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# r1\n",
    "# this will create vectors for the documents inside the `embed_documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722797bf-c54f-4bdc-b257-34a92fd34cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.embed_query(\"What's the second letter of greek alphabate\")\n",
    "\n",
    "# `embed_query` is used to get related vectors of the query is passed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bc79d-ac58-464c-a3ed-c1b27c296987",
   "metadata": {},
   "source": [
    "Embedding models : https://ollama.com/blog/embedding-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367d29d-24d6-4e04-afc8-df560fd2624b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
