{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d7cd5d-7fc5-4977-b04f-be11f066ca25",
   "metadata": {},
   "source": [
    "## Building a Chatbot :\n",
    "\n",
    "- Design and implement an LLM-powered chatbot which will able to have conversation and remember previous interaction.\n",
    "- This chatbot that will only use the language model to have a conversation.\n",
    "- Few other related concepts are available :\n",
    "    - Conversational RAG : Chat with external or private data\n",
    "    - Agent : A chatbot can take a action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a3ba93b-b431-400a-adf0-91497b6e0541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9de94b62-a923-47f9-b102-f490bac574bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f31088f37c0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f31088f5000>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "# model = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=GROQ_API_KEY)\n",
    "# model = ChatGroq(model=\"gemma-7b-it\", groq_api_key=GROQ_API_KEY)\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=GROQ_API_KEY)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e8739a5-0576-4756-8c90-2c3a2771e3af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Pranav. As a GCP Cloud AI ML Engineer, you must be working with Google Cloud Platform's AI and machine learning services. That's a cutting-edge field with a lot of exciting opportunities. \\n\\nWhat specific areas of AI and ML are you currently working on or interested in? Are you using services like TensorFlow, AutoML, or Vertex AI? Or perhaps you're exploring other GCP services like Cloud Dataflow or Cloud Storage? Let's chat about your work!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 52, 'total_tokens': 154, 'completion_time': 0.136, 'prompt_time': 0.010481001, 'queue_time': 0.004025859, 'total_time': 0.146481001}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None}, id='run-7faa25ba-f617-44d2-bafc-5e1f311d8de5-0', usage_metadata={'input_tokens': 52, 'output_tokens': 102, 'total_tokens': 154})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, I am Pranav and I am GCP Cloud AIML Engineer.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94e30808-fe96-4150-ab1c-269a9b4c68aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Pranav, and you are a GCP Cloud AIML Engineer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 139, 'total_tokens': 158, 'completion_time': 0.025333333, 'prompt_time': 0.02837531, 'queue_time': 0.004472137000000001, 'total_time': 0.053708643}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-4d7d0cbc-cc7e-4d8f-b748-fe46ece072bd-0', usage_metadata={'input_tokens': 139, 'output_tokens': 19, 'total_tokens': 158})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the Chatbot\n",
    "# made a hardcode of HumanMessage and AIMessage to see when next HumanMessage will come how AIMessage will behave\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, I am Pranav and I am GCP Cloud AIML Engineer.\"),\n",
    "        AIMessage(content=\"Hi Pranav, it's nice to meet you! \\n\\nAs a GCP Cloud AIML Engineer, you must be working on some exciting projects. \\n\\nWhat kind of work are you most passionate about in the field of AIML?  Do you have any particular areas of expertise or projects you'd like to share?\"),\n",
    "        HumanMessage(content=\"Hey, what's my name and what do I do ?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1540c-4fb0-411b-9c01-473b21e526e3",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "957f2915-99a0-48a4-a38d-ac971b920430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store ={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    '''\n",
    "    session_id will get inherited (use) to BaseChatMessageHistory to create a difference between sessions.\n",
    "    '''\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7fcf54fb-a423-4096-8520-424af25b077b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configurations={\"configurable\":{\"session_id\":\"chat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5e2d104-789c-41e9-8d21-b79e9ec2439a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am Pranav and I am GCP Cloud AIML Engineer working in Cognizant where helping the GCP customers for POCs.\")],\n",
    "    config=configurations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33f960d2-67bb-4973-bfc6-a5ca0ad6b327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Pranav. It's great that you're working as a Cloud AI ML Engineer in Cognizant, specifically helping GCP customers with Proof of Concepts (POCs). AI and ML are rapidly evolving fields, and Google Cloud Platform (GCP) provides a wide range of tools and services to support AI and ML workloads.\\n\\nAs a Cloud AI ML Engineer, what kind of POCs do you usually work on? Are you working with clients on building custom AI/ML models, deploying them on GCP, or helping them integrate with other GCP services like Vertex AI, Dataflow, or BigQuery?\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8788410c-ba55-498f-998a-8de59923d52c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You, Pranav, are a GCP Cloud AI/ML Engineer working in Cognizant, where you help GCP customers with Proof of Concepts (POCs).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 213, 'total_tokens': 250, 'completion_time': 0.049333333, 'prompt_time': 0.043540418, 'queue_time': 0.004131152000000006, 'total_time': 0.092873751}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-eaf66734-8c8d-47bd-b320-9719bd2ceaf2-0', usage_metadata={'input_tokens': 213, 'output_tokens': 37, 'total_tokens': 250})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Who am I?\")],\n",
    "    config=configurations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44ce5441-5474-4db0-a1cd-a828619e8560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Unfortunately, I don't have any information about you. This conversation just started, and we haven't discussed anything specific yet. If you'd like to share something about yourself or ask a question, I'm here to help.\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the config which mean I am chaning the \"session_id\"\n",
    "configurations1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Who am I?\")],\n",
    "    config=configurations1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c7eb7633-a389-47d3-8401-ecbab5e535f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, John. That's a common name, so I don't have any additional information about you specifically. Would you like to tell me more about yourself, or is there something particular you'd like to talk about?\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey, I am John.\")],\n",
    "    config=configurations1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff248315-cc98-4064-b68c-075f594f0ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Unfortunately, I don't know much about you, John. Since our conversation just started, I don't have any prior knowledge or personal data about you. However, I can make some educated guesses based on our conversation so far.\\n\\nYou:\\n\\n* Are a person (obviously!)\\n* Have a name, John\\n* Are conversing with a language model (me)\\n* Are interested in getting to know me or asking questions\\n\\nThat's about it, though. If you'd like to share more about yourself, I'm happy to listen and learn!\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What do you know about me?\")],\n",
    "    config=configurations1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d3ae2-0c99-4492-a785-c202bb295e0a",
   "metadata": {},
   "source": [
    "### Promp Templates :\n",
    "Prompt Templates help to turn raw user information into a content format that the LLM can work. In this case, the raw user input is just a message, which we are passing to the LLM. Now let's add a system messages with some custom instructions (will take messages as input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77e5d33c-09c5-418d-b820-162458091787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're a helpful assistance. Answer all the questions to the best of your ability.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32f7cfad-c0c4-4670-b07e-f2f3f31bf298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Deps, it's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 59, 'total_tokens': 78, 'completion_time': 0.025333333, 'prompt_time': 0.015046619, 'queue_time': 0.09693327, 'total_time': 0.040379952}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-5efd5c52-916f-4c9c-9595-91136394389b-0', usage_metadata={'input_tokens': 59, 'output_tokens': 19, 'total_tokens': 78})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi, I am Deps.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "328ff8e0-f082-4521-b34a-9c1bd9087645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ad48a18b-33a5-44fb-85a8-86a9221626e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Deps. How can I assist you today?'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations2={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am Deps.\")],\n",
    "    config=configurations2\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b661c2d2-3834-417e-a881-219768cb6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some more complexity on top of it.\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're a helpful assistance. Answer all the questions to the best of your ability in {language}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9c6f43c-ee69-4c30-97af-ab8597930201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्कार प्रानव जी, मैं आपकी सहायता करने के लिए तैयार हूँ।'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"Hi, My name is Pranav.\")],\n",
    "        \"language\":\"Hindi\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "74f6e646-eb21-4cd0-937e-c62da0778315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No wrap this mre complicated Message History class \n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7075cd20-cb39-48a3-9369-bfd9ec550785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते प्रणव जी, आपका स्वागत है! आपके Pronav का अर्थ है सपना या आकांक्षा (Pranav)। यह एक सुंदर नाम है और यह जानने पर खुशी हुई कि आप एक पेशेवर एआई इंजीनियर हैं और CTS में काम करते हैं।\\n\\nक्या आपको कोई विशिष्ट समस्या है जिसका समाधान चाहिए या आपने कुछ नए विकास के बारे में जानना चाहते हैं?'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations4={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hi, I am Pranav and I am working professional AI Engineer at CTS\")],\n",
    "     \"language\":\"Hindi\",\n",
    "    },\n",
    "    config=configurations4\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3ae1789f-264e-48d8-a2ba-24e7f5000ba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आपका नाम प्रणव है!'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What's my name?\")],\n",
    "     \"language\":\"Hindi\",\n",
    "    },\n",
    "    config=configurations4\n",
    ")\n",
    "\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
